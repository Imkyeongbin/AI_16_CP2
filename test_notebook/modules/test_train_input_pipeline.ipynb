{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "\n",
    "path_to_AI16CP2 = '../../AI_16_CP2'\n",
    "sys.path.insert(0, path_to_AI16CP2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.trainData import *\n",
    "excel_path = '../../datasets/High_Resolution/AI_Hub_gender_with_path_sheet.xlsx'\n",
    "image_data_root = '../../datasets/High_Resolution'\n",
    "df_id_label, df_paths = get_df_from_excel(excel_path, image_data_root )\n",
    "\n",
    "model_name = 'vggface'\n",
    "metric = 'euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  gender                       id_image_data_root\n",
      "0    19062421       1  ../../datasets/High_Resolution\\19062421\n",
      "1    19062431       1  ../../datasets/High_Resolution\\19062431\n",
      "2    19062521       0  ../../datasets/High_Resolution\\19062521\n",
      "3    19062531       0  ../../datasets/High_Resolution\\19062531\n",
      "4    19062542       0  ../../datasets/High_Resolution\\19062542\n",
      "..        ...     ...                                      ...\n",
      "395  19101441       1  ../../datasets/High_Resolution\\19101441\n",
      "396  19101442       0  ../../datasets/High_Resolution\\19101442\n",
      "397  19101443       1  ../../datasets/High_Resolution\\19101443\n",
      "398  19101512       1  ../../datasets/High_Resolution\\19101512\n",
      "399  19101513       0  ../../datasets/High_Resolution\\19101513\n",
      "\n",
      "[400 rows x 3 columns]\n",
      "                     path\n",
      "0     S001\\L1\\E01\\C15.jpg\n",
      "1     S001\\L1\\E01\\C16.jpg\n",
      "2     S001\\L1\\E01\\C17.jpg\n",
      "3     S001\\L1\\E01\\C19.jpg\n",
      "4     S001\\L1\\E01\\C20.jpg\n",
      "...                   ...\n",
      "4297   S006\\L9\\E03\\C5.jpg\n",
      "4298   S006\\L9\\E03\\C6.jpg\n",
      "4299   S006\\L9\\E03\\C7.jpg\n",
      "4300   S006\\L9\\E03\\C8.jpg\n",
      "4301   S006\\L9\\E03\\C9.jpg\n",
      "\n",
      "[4302 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_id_label)\n",
    "print(df_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                    ...\n",
      "1                                                    ...\n",
      "2                                                    ...\n",
      "3                                                    ...\n",
      "4                                                    ...\n",
      "                             ...                        \n",
      "395                                                  ...\n",
      "396                                                  ...\n",
      "397                                                  ...\n",
      "398                                                  ...\n",
      "399                                                  ...\n",
      "Name: id_image_data_root, Length: 400, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "def create_df_image_paths(row):\n",
    "    paths = df_paths['path'].apply(lambda x: os.path.join(row, x))\n",
    "    return pd.DataFrame(paths)\n",
    "\n",
    "# 각 행에 데이터프레임을 저장\n",
    "img_path_2dseries = df_id_label['id_image_data_root'].apply(create_df_image_paths)\n",
    "\n",
    "print(img_path_2dseries)\n",
    "print(type(img_path_2dseries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth', None)  # 각 열의 너비를 최대로 설정\n",
    "del df_id_label\n",
    "del df_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.face_detector import FacePreparer\n",
    "preparer = FacePreparer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils.function.generals import load_image\n",
    "\n",
    "\n",
    "pd.reset_option('max_colwidth')\n",
    "\n",
    "\n",
    "# 추출 불가 이미지 리스트\n",
    "invalid_image_tuple_list = []\n",
    "boom_turn = 0\n",
    "def get_img(idx, j):\n",
    "    img = None\n",
    "    if (idx, j) in invalid_image_tuple_list:\n",
    "        return None\n",
    "    df = img_path_2dseries.iloc[idx]\n",
    "    img_path = df['path'].iloc[j]\n",
    "    img_255 = load_image(img_path) \n",
    "    face_list = preparer.detect_faces(img_255, model_name)\n",
    "    if len(face_list) >0:\n",
    "        img = face_list[0] / 255 # 정규화된 동일 이미지 원본\n",
    "    else:\n",
    "        invalid_image_tuple_list.append((idx, j))\n",
    "    \n",
    "    # return [len(img_path)]*2 #test 용\n",
    "    return img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pair_img_source: 노멀라이즈된 이미지 페어\n",
    "# 이미지 페어가 (2, H, W, C) 형태로 있다고 가정합니다.\n",
    "\n",
    "def plot_pairs(img1, img2, img3, img4):\n",
    "    # 첫번째 이미지\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(img1)\n",
    "    plt.title('Origin')\n",
    "\n",
    "    # 두번째 이미지\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(img2)\n",
    "    plt.title('Different')\n",
    "    \n",
    "    # 첫번째 이미지\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(img3)\n",
    "    plt.title('Origin')\n",
    "\n",
    "    # 두번째 이미지\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(img4)\n",
    "    plt.title('Same person')\n",
    "\n",
    "    # 이미지 플롯 보여주기\n",
    "    plt.show()\n",
    "    input('Press Enter to continue...')\n",
    "\n",
    "\n",
    "\n",
    "# for idx, df in tqdm(enumerate(img_path_2dseries)):\n",
    "def generator(df_series, generator_batch= 32, num_per_id=50): # df로 된 시리즈\n",
    "    \"\"\"\n",
    "        num_per_id * 390(id) * 2 (True, False) = 최대 쌍수\n",
    "    \"\"\"\n",
    "    for idx, df in enumerate(df_series):\n",
    "        # if idx >= 1: # 테스트용\n",
    "        if idx >= len(img_path_2dseries) - 1 - 10: # 390 이상부터 랜덤 추출할 수가 적어 찾는데 시간이 많이 걸릴 수 있고, 에러가 발생할 수 있음(train, val에선 조건이 성립하지 않음)\n",
    "            return\n",
    "        \n",
    "        used_img_list = []\n",
    "        pair_img_source = None\n",
    "        while pair_img_source is None:\n",
    "            random_index = random.randint(0, len(df) - 1)\n",
    "            pair_img_source = get_img(idx, random_index) # 동일쌍 타겟\n",
    "        \n",
    "        pair_source_list = []\n",
    "        pair_target_list = []\n",
    "        label_list = []\n",
    "        \n",
    "        # 샘플 추출\n",
    "        random_numbers = random.sample(range(0, 4302), num_per_id)\n",
    "\n",
    "        for j_index, j in enumerate(random_numbers): # 0 ~ 4301\n",
    "            true_pair_img_target = get_img(idx, j) # 동일쌍 비동일쌍에서 둘다 원본으로 편성.\n",
    "            if true_pair_img_target is None:\n",
    "                continue\n",
    "            \n",
    "            false_pair_img_target = None\n",
    "            random_i = ''\n",
    "            random_j = ''\n",
    "            while_cnt = -1\n",
    "            while false_pair_img_target is None:\n",
    "                while_cnt += 1\n",
    "                if while_cnt >= len(df): #while_cnt를 inner_df 길이 이상으로 했으면 충분히 찾았다고 치고 그냥 넘어감\n",
    "                    break\n",
    "                random_i = random.randint(idx+1, len(img_path_2dseries) - 1)\n",
    "                random_j = random.randint(0, len(df) - 1)\n",
    "                if (random_i, random_j) in used_img_list: # 이미지가 이번 id(0~399) 포문중에 쓰였다면 넘어감\n",
    "                    continue\n",
    "                false_pair_img_target = get_img(random_i, random_j) # 비동일쌍 타겟\n",
    "\n",
    "            used_img_tuple = (random_i, random_j)\n",
    "            used_img_list.append(used_img_tuple)\n",
    "\n",
    "            # 모든 쌍 요소와 라벨이 존재하므로 추가할 수 있음\n",
    "            # if(count == 5):\n",
    "            #     count = 0\n",
    "            #     break\n",
    "            \n",
    "            # 구성된 샴네트워크가 (이미지, 이미지), 라벨로 받길 원하는게 아니라, [배치수, (이미지리스트, 이미지리스트), 라벨]로 받길 원함\n",
    "            pair_source_list.append(pair_img_source)\n",
    "            pair_target_list.append(true_pair_img_target)\n",
    "            label_list.append(1)\n",
    "            \n",
    "            #테스트용\n",
    "            # print(pair_img_source.shape)\n",
    "            \n",
    "            pair_source_list.append(pair_img_source)\n",
    "            pair_target_list.append(false_pair_img_target)\n",
    "            label_list.append(0)\n",
    "\n",
    "            \n",
    "                            \n",
    "            #테스트용\n",
    "            # plot_pair(pair_img_source, false_pair_img_target, pair_img_source, true_pair_img_target)\n",
    "\n",
    "            # label_list가 제너레이터 배치보다 크거나 j_index가 마지막 인덱스 이상일때\n",
    "            if len(label_list) >= generator_batch or j_index >= len(random_numbers) - 1:\n",
    "                # 리스트를 NumPy 배열로 변환\n",
    "                pair_source_array = np.array(pair_source_list, dtype=np.float32)\n",
    "                pair_source_list.clear()\n",
    "                pair_target_array = np.array(pair_target_list, dtype=np.float32)\n",
    "                pair_target_list.clear()\n",
    "                label_array = np.array(label_list, dtype=np.int32)\n",
    "                label_list.clear()\n",
    "                \n",
    "                yield (pair_source_array, pair_target_array), label_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3                                                    ...\n",
       "18                                                   ...\n",
       "202                                                  ...\n",
       "250                                                  ...\n",
       "274                                                  ...\n",
       "                             ...                        \n",
       "71                                                   ...\n",
       "106                                                  ...\n",
       "270                                                  ...\n",
       "348                                                  ...\n",
       "102                                                  ...\n",
       "Name: id_image_data_root, Length: 320, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(df_series, test_size=0.2, random_state=42):\n",
    "    train_df_series, val_df_series = train_test_split(df_series, test_size=test_size, random_state=random_state)\n",
    "    return train_df_series, val_df_series\n",
    "\n",
    "train_df_series, val_df_series = split_dataset(img_path_2dseries, test_size=0.2)\n",
    "train_df_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.face_verifier2 import Verifier2\n",
    "from utils.math import get_contrastive_loss\n",
    "import tensorflow as tf\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "verifier = Verifier2(model_name, metric)\n",
    "#############################\n",
    "verifier.model.load_weights('vggface_weights/vggface_weights_09.h5')\n",
    "#############################\n",
    "\n",
    "# 손실 함수, 평가 지표 정의\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-7)\n",
    "# opt = tf.keras.optimizers.RMSprop(learning_rate=0.0001, rho=0.9, momentum=0.9, epsilon=1e-6)\n",
    "loss = [\"binary_crossentropy\"] #contrastive(거리값으로 대조할 때) / 이진분류의 대표적 손실함수 \n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "verifier.model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=loss,\n",
    "    metrics=metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 2622)         151880384   ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " distance_layer (distanceLayer)  (None, 1)           0           ['model_1[0][0]',                \n",
      "                                                                  'model_1[1][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            2           ['distance_layer[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 151,880,386\n",
      "Trainable params: 6,877,508\n",
      "Non-trainable params: 145,002,878\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "verifier.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 224, 224, 3), (None, 224, 224, 3)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verifier.model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1920/1920 [==============================] - ETA: 0s - loss: 0.6291 - accuracy: 0.6452"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21508\\1024038444.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\scinn\\.conda\\envs\\cp2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\scinn\\.conda\\envs\\cp2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1454\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1455\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1456\u001b[1;33m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[0;32m   1457\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\scinn\\.conda\\envs\\cp2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\scinn\\.conda\\envs\\cp2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1754\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1756\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1757\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1758\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\scinn\\.conda\\envs\\cp2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\scinn\\.conda\\envs\\cp2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\scinn\\.conda\\envs\\cp2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\Users\\scinn\\.conda\\envs\\cp2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\scinn\\.conda\\envs\\cp2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\scinn\\.conda\\envs\\cp2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\scinn\\.conda\\envs\\cp2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, math\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "dir_path = \"./vggface_weights\"\n",
    "POST_FIX = '_weights_03epoch_{epoch:02d}-{val_accuracy:.3f}.h5'\n",
    "# BATCH_SIZE = 4\n",
    "BATCH_SIZE = 64\n",
    "NUM_PER_ID = 192\n",
    "# NUM_PER_ID = 1 #테스트\n",
    "EPOCHS = 3\n",
    "PATIENCE = 3\n",
    "\n",
    "# log_dir = '/logs'  # 로그가 저장될 디렉토리\n",
    "# tensorboard_callback = TensorBoard(log_dir=os.path.join(dir_path, log_dir), histogram_freq=1, update_freq=1)\n",
    "\n",
    "if not os.path.exists(dir_path):\n",
    "    os.mkdir(dir_path)\n",
    "\n",
    "output_signature = (\n",
    "    (tf.TensorSpec(shape=verifier.model.input_shape[0], dtype=tf.float32),\n",
    "     tf.TensorSpec(shape=verifier.model.input_shape[1], dtype=tf.float32)),\n",
    "    tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    ")\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    generator= lambda: generator(train_df_series, BATCH_SIZE * 2, NUM_PER_ID),\n",
    "    output_signature=output_signature,\n",
    ").repeat()\n",
    "# train_generator = generator(train_df_series, EPOCHS, BATCH_SIZE * 2, NUM_PER_ID)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    generator= lambda: generator(val_df_series, BATCH_SIZE * 2, NUM_PER_ID),\n",
    "    output_signature=output_signature,\n",
    "    # output_types=((tf.float32, tf.float32), tf.int32), #deprecated\n",
    "    # output_shapes=( (verifier.model.input_shape[0], verifier.model.input_shape[1]), None ), #deprecated\n",
    ").repeat()\n",
    "# val_generator = generator(val_df_series, EPOCHS, BATCH_SIZE * 2, NUM_PER_ID)\n",
    "\n",
    "# 데이터셋 테스트\n",
    "# for elem in train_ds.take(1):\n",
    "#     print(elem)\n",
    "# for elem in val_ds.take(1):\n",
    "#     print(elem)\n",
    "\n",
    "\n",
    "# 스텝 설정\n",
    "steps_per_epoch = math.ceil(len(train_df_series) * NUM_PER_ID * 2 / BATCH_SIZE) # 사실 미묘하게 안맞는데 비슷해서 이렇게 씀\n",
    "validation_steps = math.ceil(len(val_df_series) * NUM_PER_ID * 2 / BATCH_SIZE) # 사실 미묘하게 안맞는데 비슷해서 이렇게 씀\n",
    "\n",
    "\n",
    "run_options = tf.compat.v1.RunOptions()\n",
    "run_options.report_tensor_allocations_upon_oom = True\n",
    "\n",
    "\n",
    "# # 가중치파일 최신 10개만 남김\n",
    "# def keep_latest_n_weights(dir_path, n=10):\n",
    "#     if not os.path.exists(dir_path):\n",
    "#         os.mkdir(dir_path)\n",
    "#         return\n",
    "    \n",
    "#     weights_files = sorted([f for f in os.listdir(dir_path) if f.endswith('.h5')], \n",
    "#                            key=lambda x: os.path.getmtime(os.path.join(dir_path, x)), reverse=True)\n",
    "#     for f in weights_files[n:]:\n",
    "#         os.remove(os.path.join(dir_path, f))\n",
    "\n",
    "# LambdaCallback 설정\n",
    "keep_latest_weights_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: keep_latest_n_weights(dir_path, n=10)\n",
    ")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=f'{dir_path}/' + model_name + POST_FIX,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch', # 1에폭마다 저장함\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE)\n",
    "\n",
    "history = verifier.model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    # callbacks=[checkpoint_callback, early, tensorboard_callback],\n",
    "    callbacks=[checkpoint_callback, early],\n",
    "    batch_size = BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps= validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "verifier.model.save_weights('vggface_weights/vggface_weights_10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 224, 224, 3), (None, 224, 224, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(verifier.model.input_shape[0], verifier.model.input_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.plot import plot_history\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 True\n",
      "input_2 True\n",
      "model True\n",
      "distance_layer True\n",
      "dense True\n"
     ]
    }
   ],
   "source": [
    "for layer in verifier.model.layers:\n",
    "    print(layer.name, layer.trainable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'arcface'\n",
    "metric = 'cosine'\n",
    "learning_rate = 0.0002\n",
    "\n",
    "verifier = Verifier2(model_name, metric)\n",
    "\n",
    "# 손실 함수, 평가 지표 정의\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-7)\n",
    "# opt = tf.keras.optimizers.RMSprop(learning_rate=0.0001, rho=0.9, momentum=0.9, epsilon=1e-6)\n",
    "loss = [\"binary_crossentropy\"] # contrastive(거리값으로 대조할 때) / 이진분류의 대표적 손실함수 \n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "verifier.model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=loss,\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " inception_resnet_v1 (Functiona  (None, 512)         23497424    ['input_3[0][0]',                \n",
      " l)                                                               'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " l2_euclidean_distance_layer (L  (None, 1)           0           ['inception_resnet_v1[0][0]',    \n",
      " 2EuclideanDistanceLayer)                                         'inception_resnet_v1[1][0]']    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            2           ['l2_euclidean_distance_layer[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,497,426\n",
      "Trainable params: 23,467,826\n",
      "Non-trainable params: 29,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "verifier.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 160, 160, 3), (None, 160, 160, 3)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verifier.model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "generator() takes from 1 to 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14452\\1322467390.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtrain_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df_series\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_PER_ID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mval_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_df_series\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_PER_ID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: generator() takes from 1 to 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "import os, math\n",
    "dir_path = \"./arcface_weights\"\n",
    "BATCH_SIZE = 64\n",
    "# NUM_PER_ID * 2 가 BATCH_SIZE 미만이면 BATCH_SIZE가 의미가 없음. 어차피 NUM_PER_ID * 2 씩만 가져와서 학습하게 되기 때문.\n",
    "NUM_PER_ID = 320\n",
    "# NUM_PER_ID = 128 # test용\n",
    "EPOCHS = 5\n",
    "PATIENCE = 5\n",
    "\n",
    "if not os.path.exists(dir_path):\n",
    "    os.mkdir(dir_path)\n",
    "\n",
    "\n",
    "output_signature = (\n",
    "    (tf.TensorSpec(shape=verifier.model.input_shape[0], dtype=tf.float32),\n",
    "     tf.TensorSpec(shape=verifier.model.input_shape[1], dtype=tf.float32)),\n",
    "    tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    ")\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    generator= lambda: generator(train_df_series, BATCH_SIZE * 2, NUM_PER_ID),\n",
    "    output_signature=output_signature,\n",
    ").repeat()\n",
    "# train_generator = generator(train_df_series, EPOCHS, BATCH_SIZE * 2, NUM_PER_ID)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    generator= lambda: generator(val_df_series, BATCH_SIZE * 2, NUM_PER_ID),\n",
    "    output_signature=output_signature,\n",
    "    # output_types=((tf.float32, tf.float32), tf.int32),\n",
    "    # output_shapes=( (verifier.model.input_shape[0], verifier.model.input_shape[1]), None ),\n",
    ").repeat()\n",
    "\n",
    "\n",
    "# 스텝 설정\n",
    "steps_per_epoch = math.ceil(len(train_df_series) * NUM_PER_ID * 2 / BATCH_SIZE)\n",
    "validation_steps = math.ceil(len(val_df_series) * NUM_PER_ID * 2 / BATCH_SIZE)\n",
    "\n",
    "\n",
    "run_options = tf.compat.v1.RunOptions()\n",
    "run_options.report_tensor_allocations_upon_oom = True\n",
    "\n",
    "\n",
    "# 가중치파일 최신 10개만 남김\n",
    "def keep_latest_n_weights(dir_path, n=10):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "        return\n",
    "    \n",
    "    weights_files = sorted([f for f in os.listdir(dir_path) if f.endswith('.h5')], \n",
    "                           key=lambda x: os.path.getmtime(os.path.join(dir_path, x)), reverse=True)\n",
    "    for f in weights_files[n:]:\n",
    "        os.remove(os.path.join(dir_path, f))\n",
    "\n",
    "# LambdaCallback 설정\n",
    "keep_latest_weights_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: keep_latest_n_weights(dir_path, n=10)\n",
    ")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=f'{dir_path}/' + model_name + POST_FIX,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=False,\n",
    "    save_freq='epoch', # 1에폭마다 저장함\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE)\n",
    "\n",
    "history2 = verifier.model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint_callback, early, keep_latest_weights_callback],\n",
    "    batch_size = BATCH_SIZE,\n",
    "    verbose=1,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps= validation_steps\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset element_spec=((TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)), TensorSpec(shape=<unknown>, dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ds_count = tf.data.Dataset.from_generator(\n",
    "#     generator= lambda: generator(train_df_series, BATCH_SIZE * 2, NUM_PER_ID),\n",
    "#     output_types=((tf.float32, tf.float32), tf.int32),\n",
    "#     output_shapes=(((None, 2), (None, 2)), None),\n",
    "# )\n",
    "# ds_count.repeat(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Series' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21280\\3213669150.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m       \u001b[1;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mour_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df_series\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Series' object is not callable"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def our_generator():\n",
    "#     for i in range(1000):\n",
    "#       print(len(train_df_series))\n",
    "#       x = np.random.rand(28,28)\n",
    "#       y = np.random.randint(1,10, size=1)\n",
    "#       yield x,y\n",
    "\n",
    "# dataset = tf.data.Dataset.from_generator()\n",
    "\n",
    "# for batch, (x,y) in enumerate(dataset):\n",
    "#   pass\n",
    "\n",
    "# print(\"batch: \", batch)\n",
    "# print(\"Data shape: \", x.shape, y.shape)\n",
    "# print(x[0])\n",
    "# print(y[0])\n",
    "\n",
    "#batch:  999\n",
    "#Data shape:  (28, 28) (1,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
